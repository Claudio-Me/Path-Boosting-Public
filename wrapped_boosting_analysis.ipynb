{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import functools\n",
    "import warnings\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from classes.boosting_matrix import BoostingMatrix\n",
    "from classes.dataset import Dataset\n",
    "from settings import Settings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from collections import Counter\n",
    "from classes.pattern_boosting import PatternBoosting\n",
    "from settings import Settings\n",
    "from classes.enumeration.estimation_type import EstimationType\n",
    "from data.synthetic_dataset import SyntheticDataset\n",
    "import pandas as pd\n",
    "import copy\n",
    "from classes.analysis_patternboosting import AnalysisPatternBoosting\n",
    "from data.load_dataset import load_dataset\n",
    "from data import data_reader\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "import copy\n",
    "from data import data_reader\n",
    "from classes.wrapper_pattern_boosting import WrapperPatternBoosting\n",
    "from jupiter_notebook_functions import *\n",
    "from classes.wrapper_pattern_boosting import WrapperPatternBoosting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from typing import List, Tuple, Optional\n",
    "import warnings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Settings:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_name = \"5_k_selection_graphs\"\n",
    "\n",
    "# the model will be searched in the directory results/jupiter\n",
    "pattern_boosting_model_name = \"frequency_matrix\"\n",
    "\n",
    "n_learners = 300\n",
    "number_of_learners = [1, 5, 10, 15, 20, 25, 35] + list(range(50, n_learners + 1, 50))\n",
    "\n",
    "max_path_length = [1, 2, 3, 4, 5, 15]\n",
    "\n",
    "max_depth = 5\n",
    "\n",
    "errors_test_list = []\n",
    "errors_train_list = []\n",
    "n_learners_list = []\n",
    "labels_list = []\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max path length:  15\n",
      "max path length:  15\n",
      "max path length:  15\n",
      "Run xgb full power and on the frequency matrix with all possible paths\n",
      "Learner number:  1\n",
      "Learner number:  5\n",
      "Learner number:  10\n",
      "Learner number:  15\n",
      "Learner number:  20\n",
      "Learner number:  25\n",
      "Learner number:  35\n",
      "Learner number:  50\n",
      "Learner number:  100\n",
      "Learner number:  150\n",
      "Learner number:  200\n",
      "Learner number:  250\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with the matrix with all possible paths\n",
    "\n",
    "directory = data_reader.get_save_location(folder_relative_path=\"results/jupiter\")\n",
    "pattern_boosting = data_reader.load_data(directory=directory, filename=\"pattern_boosting_all_paths\")\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# get the frequency matrix\n",
    "print(\"get the frequency matrix\")\n",
    "'''\n",
    "if isinstance(pattern_boosting, PatternBoosting):\n",
    "    frequency_matrix = pattern_boosting.create_boosting_matrix_for(dataset)\n",
    "\n",
    "elif isinstance(pattern_boosting, WrapperPatternBoosting):\n",
    "    frequency_matrix = pattern_boosting.create_ordered_boosting_matrix(dataset)\n",
    "'''\n",
    "frequency_matrix = pd.DataFrame(pattern_boosting.boosting_matrix.get_matrix(),\n",
    "                                columns=pattern_boosting.boosting_matrix.get_header())\n",
    "\n",
    "print(len(pattern_boosting.boosting_matrix.get_header()))\n",
    "\n",
    "# run classical XGB with depth 1 using different number of learners, parallelize over the max length paths\n",
    "print(\"run classical XGB with depth 1 using different number of learners\")\n",
    "pool = ThreadPool(min(10, len(max_path_length)))\n",
    "\n",
    "xgb_err = pool.map(\n",
    "    functools.partial(get_XGB_error_and_variable_importance,\n",
    "                      frequency_matrix=copy.deepcopy(frequency_matrix),\n",
    "                      labels=dataset.labels,\n",
    "                      max_number_of_learners=number_of_learners),\n",
    "    max_path_length)\n",
    "\n",
    "xgb_test_err, xgb_train_err, variable_importance = zip(*xgb_err)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Run xgb full power and on the frequency matrix with all possible paths\n",
    "print(\"Run xgb full power and on the frequency matrix with all possible paths\")\n",
    "xgb_settings = Settings.xgb_model_parameters\n",
    "xgb_settings['max_depth'] = max_depth\n",
    "test_err_full_power_xgb, train_err_full_power_xgb, _ = get_XGB_error_and_variable_importance(\n",
    "    max_path_length=200,\n",
    "    frequency_matrix=copy.deepcopy(frequency_matrix),\n",
    "    labels=dataset.labels,\n",
    "    max_number_of_learners=number_of_learners,\n",
    "    xgb_settings=xgb_settings)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Run xgb full power and on the frequency matrix given by pattern boosting\n",
    "print(\"Run xgb full power and on the frequency matrix given by pattern boosting\")\n",
    "# load pattern boosting model, to use the headers found by the algorithm\n",
    "directory = data_reader.get_save_location(folder_relative_path=\"results/jupiter\")\n",
    "pattern_boosting = data_reader.load_data(directory=directory, filename=\"pattern_boosting_500_steps\")\n",
    "print(pattern_boosting.test_dataset)\n",
    "\n",
    "pd_pattern_boosting_matrix = pd.DataFrame(pattern_boosting.boosting_matrix.get_matrix(),\n",
    "                                          columns=pattern_boosting.boosting_matrix.get_header())\n",
    "\n",
    "test_err_full_power_xgb_on_pattern_boosting_matrix, train_err_full_power_xgb_on_pattern_boosting_matrix, _ = get_XGB_error_and_variable_importance_t(\n",
    "    max_path_length=200,\n",
    "    pattern_boosting=pattern_boosting,\n",
    "    max_number_of_learners=number_of_learners,\n",
    "    frequency_matrix=pd_pattern_boosting_matrix,\n",
    "    xgb_settings=xgb_settings)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#merging all the errors\n",
    "\n",
    "errors_test_list += xgb_test_err\n",
    "errors_train_list += xgb_train_err\n",
    "for length in max_path_length:\n",
    "    n_learners_list.append(number_of_learners)\n",
    "    labels_list.append('XGB path ' + str(length))\n",
    "\n",
    "errors_test_list.append(test_err_full_power_xgb)\n",
    "errors_train_list.append(test_err_full_power_xgb)\n",
    "n_learners_list.append(number_of_learners)\n",
    "labels_list.append('XGB depth ' + str(max_depth) + ' on all paths')\n",
    "\n",
    "errors_test_list.append(test_err_full_power_xgb)\n",
    "errors_train_list.append(test_err_full_power_xgb)\n",
    "n_learners_list.append(number_of_learners)\n",
    "labels_list.append('full XGB pattern boosting matrix')\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "errors_test_list.append(pattern_boosting.test_error)\n",
    "errors_train_list.append(pattern_boosting.train_error)\n",
    "n_learners_list.append(range(1, len(pattern_boosting.test_error) + 1))\n",
    "labels_list.append('pattern boosting')\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# saving the errors\n",
    "try:\n",
    "    old_n_learners = data_reader.load_data(directory=\"results/jupiter/plot\", filename=\"old_n_learners\")\n",
    "except:\n",
    "    warnings.warn(\"Old number of learners not found\")\n",
    "    old_n_learners = 0\n",
    "if n_learners > old_n_learners:\n",
    "    data_reader.save_data(n_learners, filename=\"old_n_learners\", directory=\"results/jupiter/plot\",\n",
    "                          create_unique_subfolder=False)\n",
    "    data_reader.save_data(errors_test_list, filename=\"errors_test_list\", directory=\"results/jupiter/plot\")\n",
    "    data_reader.save_data(errors_train_list, filename=\"errors_train_list\", directory=\"results/jupiter/plot\")\n",
    "    data_reader.save_data(n_learners_list, filename=\"n_learners_list\", directory=\"results/jupiter/plot\")\n",
    "    data_reader.save_data(labels_list, filename=\"labels_list\", directory=\"results/jupiter/plot\")\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the errors\n",
    "directory = data_reader.get_save_location(folder_relative_path=\"results/jupiter\", create_unique_subfolder=True)\n",
    "errors_test_list = data_reader.load_data(directory=directory, filename=\"errors_test_list\")\n",
    "errors_train_list = data_reader.load_data(directory=directory, filename=\"errors_train_list\")\n",
    "n_learners_list = data_reader.load_data(directory=directory, filename=\"n_learners_list\")\n",
    "labels_list = data_reader.load_data(directory=directory, filename=\"labels_list\")\n",
    "\n",
    "directory = '/Users/popcorn/PycharmProjects/pattern_boosting/results/Xgb_step_200_max_path_length_100_5_k_selection_graphs/wrapped_boosting/'\n",
    "\n",
    "wrapper_pattern_boosting = data_reader.load_data(directory=directory, filename=\"wrapper_pattern_boosting\")\n",
    "\n",
    "errors_test_list.append(wrapper_pattern_boosting.test_error)\n",
    "errors_train_list.append(wrapper_pattern_boosting.train_error)\n",
    "n_learners_list.append(range(1, len(wrapper_pattern_boosting.test_error) + 1))\n",
    "labels_list.append('wrapper pattern boosting')\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def plot_error_evolution(error_list: List[List[float]],\n",
    "                         number_of_learners_list: List[List[float]],\n",
    "                         labels: List[str],\n",
    "                         title: str = 'Evolution of the Error',\n",
    "                         y_lim: Optional[Tuple[float, float]] = None) -> None:\n",
    "    \"\"\"\n",
    "    Plots the evolution of different error series based on corresponding number of learners and error values.\n",
    "\n",
    "    :param error_list: A list of lists, where each sublist contains the error values for a different model or condition.\n",
    "    :type error_list: list[list[float]]\n",
    "    :param number_of_learners_list: A list of lists of numbers representing learners that correspond to the error values.\n",
    "    :type number_of_learners_list: list[list[float]]\n",
    "    :param labels: A list of strings that serve as labels for the plots. Must be the same length as error_list.\n",
    "    :type labels: list[str]\n",
    "    :param title: The title of the plot. Defaults to 'Evolution of the Error' if not provided.\n",
    "    :type title: str\n",
    "    :param y_lim: An optional tuple with two float values to set the limits of the y-axis. Defaults to None if not provided.\n",
    "    :type y_lim: tuple[float, float], optional\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if not error_list or not number_of_learners_list or not labels:\n",
    "        raise ValueError(\"error_list, number_of_learners_list, and labels must not be empty.\")\n",
    "\n",
    "    if len(error_list) != len(labels) or len(error_list) != len(number_of_learners_list):\n",
    "        raise ValueError(\n",
    "            f\"The number of labels ({len(labels)}) and the number of error/value series ({len(error_list)}) must match.\")\n",
    "\n",
    "    for error_values, number_of_learners_values in zip(error_list, number_of_learners_list):\n",
    "        if len(error_values) != len(number_of_learners_values):\n",
    "            raise ValueError(\"Each error sublist must be of the same length as its corresponding value sublist.\")\n",
    "\n",
    "    plt.style.use('ggplot')  # Set the plot style to 'ggplot'\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for error, number_of_learners, label in zip(error_list, number_of_learners_list, labels):\n",
    "        ax.plot(number_of_learners, error, label=label)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))  # Force x-axis to show only integer values\n",
    "\n",
    "    if y_lim is not None:\n",
    "        ax.set_ylim(y_lim)\n",
    "\n",
    "    ax.set_xlabel('Number of Learners')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_error_evolution(errors_test_list, n_learners_list, labels_list, title=\"Test Error\", y_lim=(0.00075, 0.00125))\n",
    "plot_error_evolution(errors_train_list, n_learners_list, labels_list, title=\"Train Error\", y_lim=(0.00075, 0.00125))\n",
    "print(\"done\")\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
